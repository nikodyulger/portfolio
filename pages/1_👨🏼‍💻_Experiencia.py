import streamlit as st

# Page settings and constants
PAGE_TITLE = "Experiencia"
PAGE_ICON = "üë®üèº‚Äçüíª"

EXPERIENCE = {
    "Accenture": {
        "company": ":violet[Accenture] | IA & Big Data",
        "dates": "###### Septiembre 2026 - Actualidad",
        "position": "###### Data Engineer",
        "location": "###### Madrid (Remoto)",
        "description": """
            - Dise√±o e implementaci√≥n de una arquitectura de datos en tiempo real orientada a la creaci√≥n de un Golden Record, sincronizando bases de datos on-premise con bases de datos no relacionales mediante CDC.
            - Orquestaci√≥n de procesos de carga inicial y conciliaci√≥n de datos entre sistemas, asegurando la integridad y trazabilidad de la informaci√≥n
            - Desarrollo de herramientas de automatizaci√≥n operativa para la generaci√≥n de configuraciones facilitando su mantenimiento y evoluci√≥n.
        """,
    },
    "DIVE.Tech": {
        "company": ":red[DIVE.Tech] | Soluciones IA",
        "dates": "###### Abril 2025 - Septiembre 2025",
        "position": "###### Data Engineer",
        "location": "###### Madrid (Remoto)",
        "description": """
            - Dise√±o de arquitecturas de datos batch y streaming, y de modelos de datos anal√≠ticos enfocados en la optimizaci√≥n de costes, el rendimiento anal√≠tico y la operaci√≥n del dato.
            - Implementaci√≥n de un sistema de Change Data Capture (CDC) desde PostgreSQL hacia ClickHouse, utilizando Kafka, Debezium y Pandas, garantizando consistencia y baja latencia en la sincronizaci√≥n de datos.
            - Optimizaci√≥n de consultas SQL para la explotaci√≥n anal√≠tica, mejorando tiempos de respuesta y eficiencia en el acceso a la informaci√≥n
            - Desarrollo de APIs REST, abarcando dise√±o de la l√≥gica, definici√≥n de endpoints y documentaci√≥n para facilitar la integraci√≥n con otros sistemas
            - Colaboraci√≥n t√©cnica con el equipo en la resoluci√≥n de incidencias y en la mejora continua de procesos y arquitectura
        """,
    },
    "Openbank": {
        "company": ":rainbow[Openbank] | Banco Digital",
        "dates": "###### Septiembre 2022 - Agosto 2024",
        "position": "###### Arquitecto AWS",
        "location": "###### Madrid",
        "description": """
            - Dise√±o y evoluci√≥n de arquitecturas serverless y orientadas a eventos en la nube, destinadas a la transferencia e integraci√≥n de informaci√≥n entre m√∫ltiples sistemas
            - Despliegue y gesti√≥n de infraestructura como c√≥digo, garantizando entornos reproducibles, escalables y mantenibles
            - Implementaci√≥n de mecanismos de monitorizaci√≥n y observabilidad, junto con la detecci√≥n y resoluci√≥n proactiva de incidencias, asegurando la estabilidad de los sistemas
            - Coordinaci√≥n t√©cnica entre equipos internos y terceros para la integraci√≥n de sistemas, con foco en escalabilidad, resiliencia y fiabilidad operativa
        """,
    },
    "HRPath": {
        "company": ":blue[Integra] | Consultor√≠a RRHH",
        "dates": "###### Enero 2021 - Octubre 2021",
        "position": "###### Consultor T√©cnico Junior",
        "location": "###### Albacete",
        "description": """
            - Implementaci√≥n de funcionalidades a medida en SAP HCM: n√≥minas, IRPF, correos, etc.
            - Dise√±o de APIs REST/OData para la integraci√≥n con otros sistemas
            - Creaci√≥n de aplicaciones web para gesti√≥n interna de los datos
            - Soporte y mantenimiento de incidencias
        """,
    },
    "UCLM": {
        "company": ":red[UCLM] | Universidad",
        "dates": "###### Noviembre 2020 - Julio 2021",
        "position": "###### Becario de Investigaci√≥n",
        "location": "###### Albacete",
        "description": """
            - Dise√±o, desarrollo y despliegue de aplicaciones web con AWS
            - Construcci√≥n de pipelines automatizados para extraer, transformar y cargar datos de sitios web
            - Entrenamiento de redes neuronales profundas para la clasificaci√≥n de im√°genes de puntos tur√≠sticos
            - Exploraci√≥n, limpieza y visualizaci√≥n de grandes vol√∫menes de datos
        """,
    },
}

st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON)

st.title(f"{PAGE_ICON} {PAGE_TITLE}")
st.divider()

for exp in EXPERIENCE.keys():
    col1, _, col3 = st.columns([3, 1, 1])
    with col1:
        st.subheader(EXPERIENCE[exp]["company"])
    with col3:
        st.write("")
        st.markdown(EXPERIENCE[exp]["dates"])

    col1, _, col3 = st.columns([3, 1, 1])
    with col1:
        st.markdown(EXPERIENCE[exp]["position"])
    with col3:
        st.markdown(EXPERIENCE[exp]["location"])

    st.write(EXPERIENCE[exp]["description"])
    st.divider()
